{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2186f17-7437-4390-9db3-afcd36745aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import datetime as dt\n",
    "from typing import Dict, Any, Iterable, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import psycopg2\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040ac909-ef9f-4c73-be5a-e915588096f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.openaq.org/v3\"\n",
    "\n",
    "PG_DSN = \"dbname=airquality user=postgres password=Milian112! host=localhost port=5432\"\n",
    "OPENAQ_API_KEY = \"7e4733295d8f3421127be449858a1a7cd7569a4c61e6581377453d05e436a341\"\n",
    "\n",
    "HEADERS = {\"X-API-Key\": OPENAQ_API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c096d874-7958-4e15-98d5-b25ebed8967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covers England and a bit around borders\n",
    "ENGLAND_BBOX = \"-6.5,49.8,2.2,55.9\"\n",
    "\n",
    "TARGET_PARAMS = {\"pm25\", \"no2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da18ccd-7a42-4db8-8c0f-e9cb0e04d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_conn():\n",
    "    return psycopg2.connect(PG_DSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc0e152-4bd5-4f4d-9e76-d9c52d1e290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "def fetch_json(\n",
    "    path: str,\n",
    "    params: Optional[Dict[str, Any]] = None,\n",
    "    sleep_s: float = 0.2,\n",
    "    max_retries: int = 5,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Robust OpenAQ v3 fetch with:\n",
    "    - X-API-Key auth\n",
    "    - retries + exponential backoff\n",
    "    - optional auth debugging\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    last_err = None\n",
    "\n",
    "    # ---- AUTH DEBUG (optional) ----\n",
    "    if os.getenv(\"DEBUG_AUTH\", \"0\") == \"1\":\n",
    "        print(\"AUTH DEBUG | Request URL:\", url)\n",
    "        print(\n",
    "            \"AUTH DEBUG | X-API-Key present:\",\n",
    "            \"X-API-Key\" in HEADERS and bool(HEADERS.get(\"X-API-Key\"))\n",
    "        )\n",
    "        print(\n",
    "            \"AUTH DEBUG | X-API-Key length:\",\n",
    "            len(HEADERS.get(\"X-API-Key\") or \"\")\n",
    "        )\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                headers=HEADERS,\n",
    "                params=params,\n",
    "                timeout=60\n",
    "            )\n",
    "\n",
    "            # Explicit auth failure (do not retry)\n",
    "            if response.status_code == 401:\n",
    "                raise RuntimeError(\n",
    "                    \"401 Unauthorized â€” X-API-Key missing or invalid\"\n",
    "                )\n",
    "\n",
    "            # Transient / retryable errors\n",
    "            if response.status_code in (429, 500, 502, 503, 504):\n",
    "                last_err = (\n",
    "                    response.status_code,\n",
    "                    response.text[:300]\n",
    "                )\n",
    "                backoff = min(30, (2 ** (attempt - 1)))\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "\n",
    "            # Any other non-200\n",
    "            response.raise_for_status()\n",
    "\n",
    "            time.sleep(sleep_s)\n",
    "            return response.json()\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            last_err = str(e)\n",
    "            backoff = min(30, (2 ** (attempt - 1)))\n",
    "            time.sleep(backoff)\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed after {max_retries} retries | \"\n",
    "        f\"url={url} params={params} | \"\n",
    "        f\"last_error={last_err}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5045c0a1-7506-4f85-825f-acada43182c9",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"DEBUG_AUTH\"] = \"1\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd52cad1-fb9f-4a0a-8091-66d364a88c1a",
   "metadata": {},
   "source": [
    "fetch_json(\"/locations\", params={\"bbox\": ENGLAND_BBOX, \"limit\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6738708-2acf-4ae1-a442-ff17d20268cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paginated_get(path: str, base_params: Dict[str, Any], limit: int = 100) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    OpenAQ list endpoints typically use page + limit pagination.\n",
    "    We keep going until results are empty.\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    while True:\n",
    "        params = dict(base_params)\n",
    "        params[\"limit\"] = limit\n",
    "        params[\"page\"] = page\n",
    "        payload = fetch_json(path, params=params)\n",
    "        results = payload.get(\"results\", [])\n",
    "        if not results:\n",
    "            break\n",
    "        for item in results:\n",
    "            yield item\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347a033f-4928-41de-80d2-32d362609de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_locations(conn, rows: List[Tuple]):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO stg_openaq_locations\n",
    "      (location_id, name, locality, timezone, country_code, country_name,\n",
    "       provider_id, provider_name, owner_id, owner_name, lon, lat, geom, raw)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (location_id) DO UPDATE SET\n",
    "      name=EXCLUDED.name,\n",
    "      locality=EXCLUDED.locality,\n",
    "      timezone=EXCLUDED.timezone,\n",
    "      country_code=EXCLUDED.country_code,\n",
    "      country_name=EXCLUDED.country_name,\n",
    "      provider_id=EXCLUDED.provider_id,\n",
    "      provider_name=EXCLUDED.provider_name,\n",
    "      owner_id=EXCLUDED.owner_id,\n",
    "      owner_name=EXCLUDED.owner_name,\n",
    "      lon=EXCLUDED.lon,\n",
    "      lat=EXCLUDED.lat,\n",
    "      geom=EXCLUDED.geom,\n",
    "      raw=EXCLUDED.raw,\n",
    "      loaded_at=now();\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        psycopg2.extras.execute_values(cur, sql, rows, page_size=1000)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374dc548-c718-4977-aff0-f35e72658f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_sensors(conn, rows: List[Tuple]):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO stg_openaq_sensors\n",
    "      (sensor_id, location_id, parameter_name, parameter_units,\n",
    "       datetime_first_utc, datetime_last_utc, raw)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (sensor_id) DO UPDATE SET\n",
    "      location_id=EXCLUDED.location_id,\n",
    "      parameter_name=EXCLUDED.parameter_name,\n",
    "      parameter_units=EXCLUDED.parameter_units,\n",
    "      datetime_first_utc=EXCLUDED.datetime_first_utc,\n",
    "      datetime_last_utc=EXCLUDED.datetime_last_utc,\n",
    "      raw=EXCLUDED.raw,\n",
    "      loaded_at=now();\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        psycopg2.extras.execute_values(cur, sql, rows, page_size=1000)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63111ee0-d091-4046-84a1-000a88198f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_daily(conn, rows: List[Tuple]):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO stg_openaq_sensor_daily\n",
    "      (sensor_id, date_utc, parameter_name, value, units,\n",
    "       observed_count, expected_count, coverage_pct, sd, raw)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (sensor_id, date_utc) DO UPDATE SET\n",
    "      parameter_name=EXCLUDED.parameter_name,\n",
    "      value=EXCLUDED.value,\n",
    "      units=EXCLUDED.units,\n",
    "      observed_count=EXCLUDED.observed_count,\n",
    "      expected_count=EXCLUDED.expected_count,\n",
    "      coverage_pct=EXCLUDED.coverage_pct,\n",
    "      sd=EXCLUDED.sd,\n",
    "      raw=EXCLUDED.raw,\n",
    "      loaded_at=now();\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        psycopg2.extras.execute_values(cur, sql, rows, page_size=2000)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac04efb-0a3c-4ca5-a1b3-00d0e3b64205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ts(ts_obj: Optional[Dict[str, Any]]) -> Optional[str]:\n",
    "    if not ts_obj:\n",
    "        return None\n",
    "    return ts_obj.get(\"utc\") or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ba9dad-2fcc-453a-9b45-de39e2850141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_england_locations():\n",
    "    \"\"\"\n",
    "    Pull locations inside the England-ish bbox.\n",
    "    \"\"\"\n",
    "    base_params = {\"bbox\": ENGLAND_BBOX}\n",
    "\n",
    "    buf: List[Tuple] = []\n",
    "    with pg_conn() as conn:\n",
    "        for loc in paginated_get(\"/locations\", base_params=base_params, limit=100):\n",
    "            loc_id = loc[\"id\"]\n",
    "            coords = loc.get(\"coordinates\") or {}\n",
    "            lat = coords.get(\"latitude\")\n",
    "            lon = coords.get(\"longitude\")\n",
    "\n",
    "            # Postgres can cast EWKT text to geometry automatically\n",
    "            geom_ewkt = None\n",
    "            if lat is not None and lon is not None:\n",
    "                geom_ewkt = f\"SRID=4326;POINT({lon} {lat})\"\n",
    "\n",
    "            country = loc.get(\"country\") or {}\n",
    "            provider = loc.get(\"provider\") or {}\n",
    "            owner = loc.get(\"owner\") or {}\n",
    "\n",
    "            buf.append((\n",
    "                loc_id,\n",
    "                loc.get(\"name\"),\n",
    "                loc.get(\"locality\"),\n",
    "                loc.get(\"timezone\"),\n",
    "                country.get(\"code\"),\n",
    "                country.get(\"name\"),\n",
    "                provider.get(\"id\"),\n",
    "                provider.get(\"name\"),\n",
    "                owner.get(\"id\"),\n",
    "                owner.get(\"name\"),\n",
    "                lon,\n",
    "                lat,\n",
    "                geom_ewkt,\n",
    "                json.dumps(loc)\n",
    "            ))\n",
    "\n",
    "            if len(buf) >= 2000:\n",
    "                upsert_locations(conn, buf)\n",
    "                buf.clear()\n",
    "\n",
    "        if buf:\n",
    "            upsert_locations(conn, buf)\n",
    "            buf.clear()\n",
    "\n",
    "    print(\"Loaded England bbox locations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0136783-f110-46ed-8427-5e6ba5e69cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensors_for_locations():\n",
    "    \"\"\"\n",
    "    For each location, pull sensors and keep only pm25/no2.\n",
    "    \"\"\"\n",
    "    with pg_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT location_id FROM stg_openaq_locations;\")\n",
    "            location_ids = [r[0] for r in cur.fetchall()]\n",
    "\n",
    "        sensor_rows: List[Tuple] = []\n",
    "        for loc_id in location_ids:\n",
    "            payload = fetch_json(f\"/locations/{loc_id}/sensors\")\n",
    "            for s in payload.get(\"results\", []):\n",
    "                param = (s.get(\"parameter\") or {})\n",
    "                param_name = (param.get(\"name\") or \"\").lower()\n",
    "                if param_name not in TARGET_PARAMS:\n",
    "                    continue\n",
    "\n",
    "                sensor_rows.append((\n",
    "                    s[\"id\"],\n",
    "                    loc_id,\n",
    "                    param_name,\n",
    "                    param.get(\"units\"),\n",
    "                    parse_ts(s.get(\"datetimeFirst\")),\n",
    "                    parse_ts(s.get(\"datetimeLast\")),\n",
    "                    json.dumps(s)\n",
    "                ))\n",
    "\n",
    "            if len(sensor_rows) >= 2000:\n",
    "                upsert_sensors(conn, sensor_rows)\n",
    "                sensor_rows.clear()\n",
    "\n",
    "        if sensor_rows:\n",
    "            upsert_sensors(conn, sensor_rows)\n",
    "\n",
    "    print(\"Loaded sensors (pm25/no2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9fd56c-76ca-4f02-bc74-46b5b543c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_daily_rows(rows: List[Tuple]) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Deduplicate by (sensor_id, date_utc) within a batch.\n",
    "    Keep the row with the best 'observed_count' (highest), then fall back to latest payload.\n",
    "    Tuple layout:\n",
    "      (sensor_id, day, parameter_name, value, units, observed, expected, pct_cov, sd, raw_json)\n",
    "    \"\"\"\n",
    "    best = {}\n",
    "    for row in rows:\n",
    "        key = (row[0], row[1])  # (sensor_id, date_utc)\n",
    "        observed = row[5] if row[5] is not None else -1\n",
    "\n",
    "        if key not in best:\n",
    "            best[key] = row\n",
    "        else:\n",
    "            prev = best[key]\n",
    "            prev_observed = prev[5] if prev[5] is not None else -1\n",
    "            # keep the row with higher observed_count\n",
    "            if observed > prev_observed:\n",
    "                best[key] = row\n",
    "\n",
    "    return list(best.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aea5c14-d8c5-44bb-902f-0eb25c7c6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_failure(conn, sensor_id, param_name, w_start, w_end, page, msg):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO etl_openaq_failures\n",
    "              (sensor_id, parameter_name, window_start, window_end, page, error_message)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            \"\"\",\n",
    "            (sensor_id, param_name, w_start, w_end, page, msg[:2000])\n",
    "        )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e1c374-eed6-4230-81d7-d1431440ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_daily_measurements(date_from: str, date_to: str, max_failures_per_sensor: int = 2):\n",
    "    \"\"\"\n",
    "    Pull daily aggregates from /v3/sensors/{id}/days (more reliable than /measurements/daily).\n",
    "    Uses monthly windows and ISO datetimes.\n",
    "    \"\"\"\n",
    "    date_from_d = dt.date.fromisoformat(date_from)\n",
    "    date_to_d = dt.date.fromisoformat(date_to)\n",
    "\n",
    "    windows = list(month_windows(date_from_d, date_to_d))\n",
    "    print(f\"Monthly windows: {len(windows)}\")\n",
    "\n",
    "    def to_iso_start(d: str) -> str:\n",
    "        return f\"{d}T00:00:00Z\"\n",
    "\n",
    "    def to_iso_end(d: str) -> str:\n",
    "        return f\"{d}T23:59:59Z\"\n",
    "\n",
    "    with pg_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT sensor_id, parameter_name FROM stg_openaq_sensors;\")\n",
    "            sensors = cur.fetchall()\n",
    "\n",
    "        daily_rows: List[Tuple] = []\n",
    "        failure_count = {}\n",
    "\n",
    "        for sensor_id, param_name in sensors:\n",
    "            if failure_count.get(sensor_id, 0) >= max_failures_per_sensor:\n",
    "                continue\n",
    "\n",
    "            for w_start, w_end in windows:\n",
    "                if failure_count.get(sensor_id, 0) >= max_failures_per_sensor:\n",
    "                    break\n",
    "\n",
    "                page = 1\n",
    "                while True:\n",
    "                    params = {\n",
    "                        \"datetime_from\": to_iso_start(w_start),\n",
    "                        \"datetime_to\": to_iso_end(w_end),\n",
    "                        \"limit\": 100,\n",
    "                        \"page\": page\n",
    "                    }\n",
    "\n",
    "                    try:\n",
    "                        payload = fetch_json(f\"/sensors/{sensor_id}/days\", params=params)\n",
    "                    except Exception as e:\n",
    "                        msg = str(e)\n",
    "                        print(f\"[WARN] sensor {sensor_id} days window {w_start}..{w_end} page {page} failed: {msg}\")\n",
    "                        failure_count[sensor_id] = failure_count.get(sensor_id, 0) + 1\n",
    "                        try:\n",
    "                            log_failure(conn, sensor_id, param_name, w_start, w_end, page, msg)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        break  # abandon this window\n",
    "\n",
    "                    results = payload.get(\"results\", [])\n",
    "                    if not results:\n",
    "                        break\n",
    "\n",
    "                    for r in results:\n",
    "                        # Use the period start (utc) as day key\n",
    "                        dt_from = ((r.get(\"period\") or {}).get(\"datetimeFrom\") or {}).get(\"utc\")\n",
    "                        if not dt_from:\n",
    "                            continue\n",
    "                        day = dt_from[:10]\n",
    "\n",
    "                        parameter = r.get(\"parameter\") or {}\n",
    "                        units = parameter.get(\"units\")\n",
    "\n",
    "                        coverage = r.get(\"coverage\") or {}\n",
    "                        observed = coverage.get(\"observedCount\")\n",
    "                        expected = coverage.get(\"expectedCount\")\n",
    "                        pct_cov = coverage.get(\"percentCoverage\")\n",
    "\n",
    "                        # Prefer summary.avg if present, else r[\"value\"]\n",
    "                        summary = r.get(\"summary\") or {}\n",
    "                        value = summary.get(\"avg\", r.get(\"value\"))\n",
    "                        sd = summary.get(\"sd\", r.get(\"sd\"))\n",
    "\n",
    "                        daily_rows.append((\n",
    "                            sensor_id,\n",
    "                            day,\n",
    "                            (parameter.get(\"name\") or param_name),\n",
    "                            value,\n",
    "                            units,\n",
    "                            observed,\n",
    "                            expected,\n",
    "                            pct_cov,\n",
    "                            sd,\n",
    "                            json.dumps(r)\n",
    "                        ))\n",
    "\n",
    "                    if len(daily_rows) >= 5000:\n",
    "                        batch = dedupe_daily_rows(daily_rows)\n",
    "                        upsert_daily(conn, batch)\n",
    "                        daily_rows.clear()\n",
    "\n",
    "\n",
    "\n",
    "                    page += 1\n",
    "\n",
    "        if daily_rows:\n",
    "            batch = dedupe_daily_rows(daily_rows)\n",
    "            upsert_daily(conn, batch)\n",
    "\n",
    "\n",
    "    quarantined = [sid for sid, c in failure_count.items() if c >= max_failures_per_sensor]\n",
    "    print(f\"Loaded /days aggregates. Quarantined sensors this run: {len(quarantined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "936cf520-fdd5-42d1-ad00-16495606545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_windows(date_from: dt.date, date_to: dt.date):\n",
    "    \"\"\"\n",
    "    Yield (start_date, end_date) as YYYY-MM-DD strings, month by month.\n",
    "    end_date is exclusive-ish for safety (we'll pass to API as inclusive range; overlap is ok due to upsert PK).\n",
    "    \"\"\"\n",
    "    cur = dt.date(date_from.year, date_from.month, 1)\n",
    "    end = dt.date(date_to.year, date_to.month, 1)\n",
    "\n",
    "    while cur <= end:\n",
    "        # next month\n",
    "        if cur.month == 12:\n",
    "            nxt = dt.date(cur.year + 1, 1, 1)\n",
    "        else:\n",
    "            nxt = dt.date(cur.year, cur.month + 1, 1)\n",
    "\n",
    "        start_str = str(max(cur, date_from))\n",
    "        # Use the last day of the month or date_to, whichever is earlier\n",
    "        end_day = min(nxt - dt.timedelta(days=1), date_to)\n",
    "        end_str = str(end_day)\n",
    "\n",
    "        yield start_str, end_str\n",
    "        cur = nxt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbe60586-c011-4df6-baa0-18481022f6bc",
   "metadata": {},
   "source": [
    "sensor_id = 12626392  # from your sample: pm25 sensor\n",
    "params = {\n",
    "  \"datetime_from\": \"2025-10-01T00:00:00Z\",\n",
    "  \"datetime_to\": \"2025-10-31T23:59:59Z\",\n",
    "  \"limit\": 100,\n",
    "  \"page\": 1\n",
    "}\n",
    "days = fetch_json(\"/sensors/12626392/days\", params=params)\n",
    "print(len(days.get(\"results\", [])))\n",
    "\n",
    "results = daily.get(\"results\", [])\n",
    "print(\"Results count:\", len(results))\n",
    "print(\"Meta:\", daily.get(\"meta\"))\n",
    "\n",
    "if results:\n",
    "    print(\"First result:\", results[0])\n",
    "else:\n",
    "    print(\"No results returned for this sensor + date window.\")\n",
    "    print(\"Full response keys:\", list(daily.keys()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4849309-dabc-48e6-934f-6cae42511b6c",
   "metadata": {},
   "source": [
    "loc = fetch_json(\"/locations/60\")  # Haringey Roadside from your sample\n",
    "print(\"Location datetimeLast:\", loc[\"results\"][0][\"datetimeLast\"][\"utc\"])\n",
    "\n",
    "sensors = loc[\"results\"][0][\"sensors\"]\n",
    "print(\"Sensors:\", [(s[\"id\"], s[\"parameter\"][\"name\"]) for s in sensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cb04a5-2d5a-452d-84ff-3ad7ac1ba72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded England bbox locations.\n",
      "Loaded sensors (pm25/no2).\n",
      "Monthly windows: 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m load_england_locations()\n\u001b[32m      5\u001b[39m load_sensors_for_locations()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mload_daily_measurements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_from\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_to\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoday\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mload_daily_measurements\u001b[39m\u001b[34m(date_from, date_to, max_failures_per_sensor)\u001b[39m\n\u001b[32m     36\u001b[39m params = {\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdatetime_from\u001b[39m\u001b[33m\"\u001b[39m: to_iso_start(w_start),\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdatetime_to\u001b[39m\u001b[33m\"\u001b[39m: to_iso_end(w_end),\n\u001b[32m     39\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlimit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m,\n\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m\"\u001b[39m: page\n\u001b[32m     41\u001b[39m }\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     payload = \u001b[43mfetch_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/sensors/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msensor_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/days\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     46\u001b[39m     msg = \u001b[38;5;28mstr\u001b[39m(e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mfetch_json\u001b[39m\u001b[34m(path, params, sleep_s, max_retries)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, max_retries + \u001b[32m1\u001b[39m):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# Explicit auth failure (do not retry)\u001b[39;00m\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m401\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\site-packages\\urllib3\\connection.py:571\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    568\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    574\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Air_Pollution\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start = dt.date(2023, 9, 1)\n",
    "today = dt.date.today()\n",
    "\n",
    "load_england_locations()\n",
    "load_sensors_for_locations()\n",
    "load_daily_measurements(date_from=str(start), date_to=str(today))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
